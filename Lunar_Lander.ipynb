{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "U642nEXJyisS"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rewardList = []\n",
        "\n",
        "class CustomCallback(BaseCallback):\n",
        "  def __init__(self, verbose: int = 0):\n",
        "    super().__init__(verbose)\n",
        "\n",
        "  def _on_training_end(self) -> None:\n",
        "    rewardList.append(self.locals[\"rewards\"][0])"
      ],
      "metadata": {
        "id": "tux5pGXCNlQb"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1bnoPEnVQTy"
      },
      "outputs": [],
      "source": [
        "env = gym.make('LunarLander-v2')\n",
        "\n",
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=64,\n",
        "    verbose=1 # Vizualização do treinamento\n",
        ")\n",
        "\n",
        "# Rodando vários treinos separadamente para observar a evolução em um gráfico\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())\n",
        "model.learn(total_timesteps=500000, callback=CustomCallback())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(rewardList)\n",
        "plt.xlabel('Episódio')\n",
        "plt.ylabel('Recompensa')\n",
        "plt.title('Episódio x Recompensa')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GvCCtVaKTJh6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMXTISUTKt4vuBtfFVt/XPJ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}